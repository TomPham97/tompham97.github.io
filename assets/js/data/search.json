[ { "title": "Hands-Free Machine Learning With Auto-Sklearn 2", "url": "/posts/auto-sklearn-2-titanic/", "categories": "iPython Notebook", "tags": "automl, scikit-learn, classification, titanic, tabular, auto-sklearn2, Kaggle", "date": "2022-08-27 00:00:00 +0200", "snippet": "Auto-Sklearn is a library for automatic machine learning developed by AutoML group from Freibug-Hannover, Germany.Generate tabular classification prediction using auto-sklearn 2Main components of the library:# Import librariesimport autosklearn.experimental.askl2import autosklearn.metrics# Configure model parametersclassifier = autosklearn.experimental.askl2.AutoSklearn2Classifier( time_left_for_this_task = 600, # in seconds metric = autosklearn.metrics.roc_auc)# Fit modelclassifier.fit(X_train, y_train)# Predict on test datay_pred = classifier.predict(X_test)To find out more about other auto-sklearn applications, visit the examples webpage.This notebook is available on GitHub or to be downloaded here.Note: to install auto-sklearn on MacOS, use the commands below. Additional details can be found in this comment.brew install swigbrew link swigpip install -U auto-sklearnDownload the dataset from KaggleThe dataset being used is from the Kaggle Titanic competition.import fastkaggleprint(\"fastkaggle version: \", fastkaggle.__version__)fastkaggle version: 0.0.7comp = 'titanic' # competition namepath = fastkaggle.setup_comp(comp, install = 'fastai \"timm &gt;= 0.6.2.dev0\"')# Import basic dependencies such as np, pdimport fastaifrom fastai.imports import *print(\"fastai version: \", fastai.__version__)fastai version: 2.7.9!ls {path}gender_submission.csv test.csv train.csvProcess and clean the dataAdditional transformation and normalization are handled byauto-sklearn 2.df = pd.read_csv(path/'train.csv', index_col = 'PassengerId')df.head() Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked PassengerId 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0 1 0 PC 17599 71.2833 C85 C 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S Define data features(X_train) and label(y_train).y_train = df['Survived']X_train = df.drop(['Survived', 'Name'], axis = 1)Since auto-sklearn 2 does not accept string columns, it is necessary to convert them into categorical columns.# Create a function that finds categorical columns and label them as such## Import dependencyfrom fastai.tabular.all import *def to_cat(df = df): ''' Convert string-type columns of a dataframe into categorical columns ''' # Identify string/categorical columns in the dataframe _, cat = cont_cat_split(df, 1) # Convert to categorical type using for loops for col in cat: df[col] = pd.Categorical(df[col])to_cat(X_train)X_train.head() Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked PassengerId 1 3 male 22.0 1 0 A/5 21171 7.2500 NaN S 2 1 female 38.0 1 0 PC 17599 71.2833 C85 C 3 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 4 1 female 35.0 1 0 113803 53.1000 C123 S 5 3 male 35.0 0 0 373450 8.0500 NaN S Data explorationThe package pandas_profiling provide quick and valuable insights into the data.import pandas_profilingprint(\"pandas_profiling version: \", pandas_profiling.__version__)pandas_profiling version: 3.2.0X_train.profile_report(progress_bar = False).to_notebook_iframe()# Use .to_notebook_iframe() for HTML format or .to_widgets() for built in widget viewConfigure and train the modelimport autosklearn print(\"autosklearn version: \", autosklearn.__version__)autosklearn version: 0.14.7import autosklearn.experimental.askl2import autosklearn.metrics# Configure model parameterscls = autosklearn.experimental.askl2.AutoSklearn2Classifier( seed = 42, time_left_for_this_task = 600, # in seconds metric = autosklearn.metrics.roc_auc, memory_limit = None, n_jobs = -1) # Use all CPUs available%%capture# Train the modelcls.fit(X_train, y_train)[WARNING] [2022-08-25 04:49:26,365:Client-AutoML(42):870bbeda-2420-11ed-af95-acde48001122] Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (599.729022)[WARNING] [2022-08-25 04:49:26,365:Client-AutoML(42):870bbeda-2420-11ed-af95-acde48001122] Capping the per_run_time_limit to 299.0 to have time for a least 2 models in each process.print(cls.sprint_statistics())auto-sklearn results: Dataset name: 870bbeda-2420-11ed-af95-acde48001122 Metric: roc_auc Best validation score: 0.884487 Number of target algorithm runs: 232 Number of successful target algorithm runs: 232 Number of crashed target algorithm runs: 0 Number of target algorithms that exceeded the time limit: 0 Number of target algorithms that exceeded the memory limit: 0To save the progress thus far, we can use fastai’s function save_pickle to store the trained model.save_pickle('cls.pkl', cls)If the pickled model needs to be accessed later, run the following:cls = load_pickle('cls.pkl')Model insightsThe contents of the model ensemble can be viewed below.print(cls.leaderboard()) rank ensemble_weight type cost durationmodel_id 115 1 0.02 passive_aggressive 0.117159 3.054357164 2 0.02 passive_aggressive 0.119444 2.595886175 3 0.92 sgd 0.121888 2.583323159 4 0.04 sgd 0.124069 2.279986import PipelineProfiler%pip show pipelineprofilerName: pipelineprofilerVersion: 0.1.18Summary: Pipeline Profiler tool. Enables the exploration of D3M pipelines in Jupyter NotebooksHome-page: https://github.com/VIDA-NYU/PipelineVisAuthor: Jorge Piazentin Ono, Sonia Castelo, Roque Lopez, Enrico Bertini, Juliana Freire, Claudio SilvaAuthor-email: jorgehpo@nyu.eduLicense: UNKNOWNLocation: /Users/tompham/Library/Python/3.10/lib/python/site-packagesRequires: networkx, notebook, numpy, python-dateutil, scikit-learn, scipyRequired-by: Note: you may need to restart the kernel to use updated packages.profiler_data = PipelineProfiler.import_autosklearn(cls)PipelineProfiler.plot_pipeline_matrix(profiler_data)Use the trained model to make predictionsProcess the test data similarly to the trained features(X_train).df_test = pd.read_csv(path/'test.csv', index_col = 'PassengerId')df_test = df_test.drop('Name', axis = 1)to_cat(df_test)df_test.head() Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked PassengerId 892 3 male 34.5 0 0 330911 7.8292 NaN Q 893 3 female 47.0 1 0 363272 7.0000 NaN S 894 2 male 62.0 0 0 240276 9.6875 NaN Q 895 3 male 27.0 0 0 315154 8.6625 NaN S 896 3 female 22.0 1 1 3101298 12.2875 NaN S # Make predictionprediction = cls.predict(df_test)# Convert the prediction to dataframe from ndarrysubm = pd.DataFrame(prediction, index = df_test.index, columns = ['Survived'])Save the prediction as a .csv file.subm.to_csv('subm.csv')# View the first few rows!head subm.csvPassengerId,Survived892,0893,1894,0895,0896,1897,0898,1899,0900,1Submit the prediction directly to the Kaggle competition. View the scores in this webpage.# Submit to competitionfrom kaggle import apiapi.competition_submit_cli('subm.csv', # file name 'auto-sklearn 2 - 10m', # version description comp) # competition name100%|██████████| 2.77k/2.77k [00:00&lt;00:00, 5.35kB/s]Successfully submitted to Titanic - Machine Learning from DisasterThis submission has an accuracy score of 79.186%, which is top 6% of all submissions. Note: there are numerous top predictions with 100% accuracy from cheating." }, { "title": "Clothe Classifier - FastAI Model", "url": "/posts/clothe-classifier-fastai-model/", "categories": "iPython Notebook", "tags": "fastai, clothe, classifier, deep learning", "date": "2022-08-02 00:00:00 +0200", "snippet": "Train a fastai model to recognize clothing items such as shirts, pants, socks, and dressesInstall dependencies#NB: Kaggle requires phone verification to use the internet or a GPU. If you haven't done that yet, the cell below will fail# This code is only here to check that your internet is enabled. It doesn't do anything else.# Here's a help thread on getting your phone number verified: https://www.kaggle.com/product-feedback/135367import socket,warningstry: socket.setdefaulttimeout(1) socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))except socket.error as ex: raise Exception(\"STOP: No internet. Click '&gt;|' in top right and set 'Internet' switch to on\")#hide!pip install -Uqq fastbookimport fastbookfastbook.setup_book()#hidefrom fastbook import *from fastai.vision.widgets import *Create categories and a data folderclothe_types = 'shirt', 'pants', 'dress', 'socks'path = Path('clothes')if not path.exists(): path.mkdir() for o in clothe_types: dest = (path/o) dest.mkdir(exist_ok = True) results = search_images_ddg(f'{o}') download_images(dest, urls=results)fns = get_image_files(path)fns(#591) [Path('clothes/dress/b5ac9ea6-87fb-4173-82d4-326138004cce.jpg'),Path('clothes/dress/0435519e-a442-422a-8401-c46d3fd106c3.jpg'),Path('clothes/dress/cd477bd9-aa97-40ba-9189-0cf46d211814.jpg'),Path('clothes/dress/690eaed8-ded2-4e0c-b3c1-ef9b72ad4027.jpg'),Path('clothes/dress/d866ee79-19d7-4932-940f-25e24049e6ea.jpg'),Path('clothes/dress/87de9d66-73e3-402e-92e1-a0129d1d6203.jpg'),Path('clothes/dress/6eaeeb1d-143f-4594-ad30-356359195955.jpg'),Path('clothes/dress/bcc646fb-258f-4f39-828c-77007d3d776a.jpg'),Path('clothes/dress/31dbf446-e338-4dab-bff6-06aaec0758b2.jpg'),Path('clothes/dress/6a77e28e-ff9b-4952-9421-fdfb180a6da2.jpg')...]Unlink files with broken urlsfailed = verify_images(fns)failed(#29) [Path('clothes/shirt/e81797ad-9dcc-44d5-81f7-1913b7d5d298.jpg'),Path('clothes/shirt/423f8260-5a47-4429-81ac-47e1bc867a38.jpg'),Path('clothes/shirt/bd49a72c-4202-4b5c-9592-7e9f37164d69.jpg'),Path('clothes/shirt/7aea9759-c319-43bb-9208-9894f0715584.jpg'),Path('clothes/shirt/c10951ed-2743-45ce-b381-50e036c090d3.jpg'),Path('clothes/pants/e0c24d0d-45d9-402d-a309-f04c56dab26b.jpg'),Path('clothes/pants/c88597d5-cba7-4e5a-8d94-3f5bec7b741f.jpg'),Path('clothes/pants/df3cd9c6-3079-4eab-a413-31ef341eef3c.jpg'),Path('clothes/pants/a2c001c4-9ccb-4013-9f94-9ecb8f80ba59.jpg'),Path('clothes/pants/7505ecb2-5f60-495d-a190-569c89c56b70.jpg')...]failed.map(Path.unlink)(#29) [None,None,None,None,None,None,None,None,None,None...]Create a datablock to import and split the data into train and test setsclothe = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct = 0.2, seed = 0), get_y = parent_label, item_tfms = Resize(128))Transform and augment the dataclothe = clothe.new( item_tfms = RandomResizedCrop(224, min_scale = 0.5), batch_tfms = aug_transforms())dls = clothe.dataloaders(path)Apply a fastai vision model to the dataSee articleby Jeremy Howard about which model is best for image classificationList of Pytorch image models%%capture!pip install timmimport timmtimm.list_models('convnext*')['convnext_base', 'convnext_base_384_in22ft1k', 'convnext_base_in22ft1k', 'convnext_base_in22k', 'convnext_large', 'convnext_large_384_in22ft1k', 'convnext_large_in22ft1k', 'convnext_large_in22k', 'convnext_nano', 'convnext_nano_hnf', 'convnext_nano_ols', 'convnext_small', 'convnext_small_384_in22ft1k', 'convnext_small_in22ft1k', 'convnext_small_in22k', 'convnext_tiny', 'convnext_tiny_384_in22ft1k', 'convnext_tiny_hnf', 'convnext_tiny_in22ft1k', 'convnext_tiny_in22k', 'convnext_xlarge_384_in22ft1k', 'convnext_xlarge_in22ft1k', 'convnext_xlarge_in22k']Select a model to use for traininglearn = vision_learner(dls, resnet34, metrics = error_rate)learn.fine_tune(4)Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth 0%| | 0.00/83.3M [00:00&lt;?, ?B/s] epoch train_loss valid_loss error_rate time 0 1.736452 0.402375 0.125000 00:25 /root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( epoch train_loss valid_loss error_rate time 0 0.562999 0.346020 0.098214 00:26 1 0.438043 0.349277 0.080357 00:26 2 0.311372 0.299984 0.071429 00:26 3 0.261189 0.276312 0.071429 00:26 /root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn(/root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn(/root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn(/root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn(Investigate the performance of the modelinterp = ClassificationInterpretation.from_learner(learn)interp.plot_confusion_matrix()Data points with the highest lossesEither wrong results with high confidence or correct results with low confidenceinterp.plot_top_losses(10, nrows = 2, figsize = (17,4))Clean the datacleaner = ImageClassifierCleaner(learn)cleaner/root/mambaforge/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn(VBox(children=(Dropdown(options=('dress', 'pants', 'shirt', 'socks'), value='dress'), Dropdown(options=('Train…for idx in cleaner.delete(): cleaner.fns[idx].unlink()for idx, cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)Upload the model to HuggingFace hubInstall git-lfs, a dependency for uploading to the hub!sudo apt-get install git-lfs!git lfs installReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following NEW packages will be installed: git-lfs0 upgraded, 1 newly installed, 0 to remove and 66 not upgraded.Need to get 2129 kB of archives.After this operation, 7662 kB of additional disk space will be used.Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2129 kB]Fetched 2129 kB in 1s (3165 kB/s) Selecting previously unselected package git-lfs.(Reading database ... 54953 files and directories currently installed.)Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...Unpacking git-lfs (2.3.4-1) ...Setting up git-lfs (2.3.4-1) ...Processing triggers for man-db (2.8.3-2ubuntu0.1) ...Updated git hooks.Git LFS initialized.Login into the hub with ‘write’ token accessfrom huggingface_hub import notebook_loginnotebook_login()VBox(children=(HTML(value='&lt;center&gt; &lt;img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…from huggingface_hub import push_to_hub_fastairepo_id = \"tompham97/clothe-classifier\"push_to_hub_fastai(learner = learn, repo_id = repo_id)/notebooks/clothe-identifier/tompham97/clothe-classifier is already a clone of https://huggingface.co/tompham97/clothe-classifier. Make sure you pull the latest changes with `repo.git_pull()`.Upload file model.pkl: 0%| | 3.34k/83.4M [00:00&lt;?, ?B/s]To https://huggingface.co/tompham97/clothe-classifier 1309dae..6cc6459 main -&gt; main'https://huggingface.co/tompham97/clothe-classifier/commit/6cc645921e3acaf7823a92cc52d1acbac83c8737'" } ]
